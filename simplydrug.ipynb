{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplydrug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def exception_handler(func):\n",
    "    \"\"\"Exception handler helper function.\n",
    "    :param func: any function.\"\"\"\n",
    "    \n",
    "    def wrapper_func(*args, **kwargs): \n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            print(f'{func.__name__} exception: ')\n",
    "            print(e)\n",
    "            return None\n",
    "    return wrapper_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Plate Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "#export\n",
    "def add_layout(df = None, layout_path = None, chem_path = None, chem_plate = None): \n",
    "    \"\"\"Add_layout function updates DataFrame containing measurements with descriptors columns taken from plate layout excel file.  \n",
    "    Sheet names in the layout file are translated to column names in the updated DataFrame.\n",
    "    :param df: pandas DataFrame with the measurements.\n",
    "    :param layout_path: path to layout xlsx file.\n",
    "    :param chem_path: path to chemical library file, optional.\n",
    "    :param chem_library: name of the chemical library plate, optional.\n",
    "    :return: DataFrame with added plate layout columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    layout = pd.DataFrame()\n",
    "    for sheet in pd.ExcelFile(layout_path).sheet_names:   # create columns from excel file\n",
    "        layout[sheet] = np.asarray(pd.ExcelFile(layout_path).parse(sheet)).reshape(-1)\n",
    "        print('Added ', sheet)\n",
    "   \n",
    "    if chem_path and chem_plate: # add compound IDs\n",
    "        compounds = pd.read_csv(chem_path, low_memory = False)\n",
    "        layout = pd.merge(layout, compounds[compounds.Plate == chem_plate], how = 'left', on = 'Well')\n",
    "        print('Added compounds: ',chem_plate,'\\n') \n",
    "\n",
    "    else:\n",
    "        print('Chemical library not requested')\n",
    "        \n",
    "    output = pd.merge(df, layout, how = 'left', on = 'Well') \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\">Add_layout function takes DataFrame, the path to layout excel file, the path to chemical library and plate name, and returns an updated DataFrame with added layout columns. We use a layout excel file to describe the experimental design, and the names of the excel sheets become the names of the columns in a final data table. Each excel sheet contains a table with dimensions of the experiment plate (usually 96 or 384-well plates) and represents some aspect of the layout - well ID, treatment, cell density, compound ID, compound concentration, etc.\n",
    "The layout file must contain sheets named 'Well' and 'Status'. The 'Well' table lists well IDs, and the 'Status' can contain either 'Sample', 'Positive' or 'Negative' control, or 'Reference' values. 'Reference' wells are excluded from calculations. The function add_layout merges measurements and layout by the 'Well' column.</div>\n",
    "\n",
    "<img style=\"float: left; margin-right:700px\"  width=\"850\" src=\"hts_notebooks/hts_images/layout.png\" > \n",
    "\n",
    "<div align=\"justify\"> Next, we need to import compound ids from chemical library. There are two options. We can fill compound ids manually in the layout excel, or we can give to the function the plate name from defined library. In this module, we will use example_chemicals.csv file located in Resources. The name of the library is 'example_library', it contains random compounds divided into 3 plates: 'ex_plate1', 'ex_plate2', and 'ex_plate3'\n",
    "For example, to load compounds from plate 3 of the library, we will pass to the function chem_path = '..//resources//compounds//example_chemicals.csv, and chem_plate = 'ex_plate3'.</div>\n",
    "   \n",
    "    \n",
    "<img style=\"float: left; margin-right:700px\"  width=\"750\" src= \"hts_notebooks/hts_images/chemlib.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def order_wells(x = None): \n",
    "    import re\n",
    "    \"\"\"Orders wells as they appear in the plate. \n",
    "    :param x: list of wells.\n",
    "    :return: Ordered list of wells.\"\"\"\n",
    "    convert = lambda text: int(text) if text.isdigit() else text \n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ]\n",
    "    return sorted(x, key = alphanum_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A1', 'A2', 'A10', 'A11', 'A12']\n"
     ]
    }
   ],
   "source": [
    "print(order_wells(['A10', 'A11', 'A12', 'A1','A2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def hts_heatmap(df = None, layout_path = None, features = None, save_as = None, path = None):\n",
    "    \"\"\"Takes DataFrame, list of features, a path to layout file, and the output folder and creates a plate heatmap for the input features.\n",
    "    :param df: pandas DataFrame with the data.\n",
    "    :param layout_path: path to layout xlsx file.\n",
    "    :param features: list of features to build heatmaps on.\n",
    "    :param save_as: filename to save the resulting figure, optional.\n",
    "    :param path: path to the output folder to save the resulting figure, optional.\n",
    "    :return: None. \"\"\"\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.colors as colors\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    # merge data with well names and status\n",
    "    layout = pd.DataFrame({'Well':np.asarray(pd.ExcelFile(layout_path).parse('Well')).reshape(-1), \n",
    "                      'Status': np.asarray(pd.ExcelFile(layout_path).parse('Status')).reshape(-1)})\n",
    "    data = pd.merge(layout, df.groupby('Well').mean(), how = 'left', on ='Well').set_index('Well', drop = False)\n",
    "    samples = data[data['Status'] == 'Sample'].dropna() \n",
    "    \n",
    "    # define plate format\n",
    "    if data.shape[0] == 384: \n",
    "        plate_reshape = (16,24) # number of rows, number of columns for 384\n",
    "        yticks=['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P']\n",
    "        xticks=['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22', '23','24']\n",
    "    elif data.shape[0] == 96:\n",
    "        plate_reshape = (8,12) # number of rows, number of columns for 96\n",
    "        yticks=['A','B','C','D','E','F','G','H']\n",
    "        xticks=['1','2','3','4','5','6','7','8','9','10','11','12']         \n",
    "    else: \n",
    "        print('Unknown plate format - cannot generate the heatmaps')\n",
    "        \n",
    "    # order wells properly\n",
    "    ordered_data =  pd.DataFrame()\n",
    "    for well in order_wells(data.Well):\n",
    "        ordered_data = ordered_data.append(data.loc[well,:])  \n",
    "        \n",
    "    # build heatmap for each feature\n",
    "    for f in features:        \n",
    "        plate_view = ordered_data[f].values.reshape(plate_reshape) \n",
    "        plate_view[np.isnan(plate_view)] = samples[f].mean() # fill missing values with sample mean value\n",
    "        vmin = samples[f].mean() - 3*(samples[f].std()) # min value for the heatmap\n",
    "        vmax = samples[f].mean() + 3*(samples[f].std()) # min value for the heatmap\n",
    "        \n",
    "        # plot\n",
    "        ax = sns.heatmap(plate_view, vmin, vmax, center = samples[f].mean(), yticklabels = yticks, xticklabels = xticks, cmap = 'RdBu_r')\n",
    "        ax.set_yticklabels(yticks, rotation = 0) \n",
    "        ax.set_xticklabels(xticks,rotation = 0)\n",
    "        ax.set_title(f + ' \\n')\n",
    "        fig = ax.get_figure()\n",
    "        fig.set_size_inches(7, 4)\n",
    "        if path:\n",
    "            plt.savefig(path + '//' + f + save_as, bbox_inches = 'tight', dpi = 600)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def sum_statistics(df = None, feature = None):\n",
    "    \"\"\"Takes DataFrame and calculates summary statistics for the experiment. The data must contain the 'Status' column, defining each row as 'Sample', 'Positive' or 'Negative' control, or 'Reference'.  'Reference' wells are excluded from the analysis.\n",
    "    :param df: pandas DataFrame with the data.\n",
    "    :param feature: feature to calculate statistics.\n",
    "    :return: summary statistics DataFrame.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from scipy import stats\n",
    "    \n",
    "    st = None\n",
    "    df = df[df.Status != 'Reference'][[feature, 'Status']]\n",
    "    st = df.groupby(['Status']).agg([np.size, np.mean, np.std, np.var])\n",
    "    st.columns = st.columns.droplevel()\n",
    "    st['Feature'] = feature  \n",
    "    \n",
    "    if 'Positive' in df['Status'].unique() and 'Negative' in df['Status'].unique(): \n",
    "        st['Z_factor'] = 1 - 3*(st.at['Positive','std'] + st.at['Negative','std'])/abs(st.at['Positive','mean'] - st.at['Negative','mean'])  \n",
    "        st['SB'] = st.at['Positive','mean']/st.at['Negative','mean']\n",
    "        st = st.reset_index()[['Feature', 'Status', 'size', 'mean', 'std', 'var', 'Z_factor', 'SB' ]]\n",
    "    else:\n",
    "        print('sum_statistics: Failed calculate Z factor. Positive or Negative control is missing.')\n",
    "        st = st.reset_index()[['Feature', 'Status', 'size', 'mean', 'std', 'var']]\n",
    "        pass\n",
    "    return st\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Z-score Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def normalize_z(df = None, feature = None):\n",
    "    \"\"\"Takes DataFrame with measurements and feature name and adds a column with \n",
    "    normalized values of the feature.\n",
    "    :param df: pandas DataFrame with the data.\n",
    "    :param feature: name of the feature to normalize.\n",
    "    :return: DataFrame with new column containing z-normalized feature values.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    mean = df[df['Status'] == 'Sample'][[feature]].mean()\n",
    "    std = df[df['Status'] == 'Sample'][[feature]].std()  \n",
    "    df[feature + '_norm'] =  df[feature].apply(lambda x:(x - mean)/std)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def histogram_feature(df = None, feature = None, save_as = None, path = None):\n",
    "    \"\"\"Creates histogram of the input feature.\n",
    "    :param df: pandas DataFrame with the data.\n",
    "    :param feature: name of the feature to build histogram.\n",
    "    :param save_as: filename to save the resulting figure, optional.\n",
    "    :param path: path to the output folder to save the resulting figure, optional.\n",
    "    :return: None.\"\"\"\n",
    "    import pandas as pd\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.colors as colors\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    sns.distplot(df[feature].values)\n",
    "    plt.plot([-2, -2], [0, 0.5], color = 'r', linestyle = '--', lw = 1.7)\n",
    "    plt.plot([2, 2], [0, 0.5], color = 'r', linestyle = '--', lw = 1.7)\n",
    "    if path:\n",
    "        plt.savefig(path + '//' + save_as, bbox_inches = 'tight', dpi = 600)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Growth Score functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def calculate_growth_score(df = None): \n",
    "    \"\"\"Calculates growth scores from time series data.\n",
    "    :param df: pandas DataFrame with time-series data.\n",
    "    :return: DataFrame with growth scores.\"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    df = df.astype(float).sort_values(['Time']) # sort by time\n",
    "    times = df['Time'].values.astype(int)\n",
    "    # create time-series table\n",
    "    ts_data = pd.DataFrame()\n",
    "    for name, data in df.drop(columns = ['Time']).iteritems():\n",
    "        ts_data = ts_data.append(pd.DataFrame({'Well': name, 'Time': times, 'OD': data}))\n",
    "    \n",
    "    # calculate drowth score\n",
    "    score_data = pd.DataFrame()\n",
    "    for name, well in ts_data.groupby('Well'):\n",
    "        well = well.copy()\n",
    "        well['past'] = np.append(well['OD'].values[0], well['OD'].values[:-1])\n",
    "        well['grate'] = (well['OD'] - well['past'])/well['past']\n",
    "        well['gscore'] = (well['OD'].max() - well['OD'].values[0]) + well['grate'].max()*0.25        \n",
    "        score_data = score_data.append(well)\n",
    "        \n",
    "    score_data = score_data.drop(columns = ['past']) \n",
    "    return score_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\"> This function used to calculate Growth Scores from time-series data. The Growth Score is defined by three parameters of the Zwietering (Zwietering et al., 1990) bacterial growth curve - the starting absorbance y0, biomass yield  A, and the maximum growth rate μ:\n",
    "</div>  \n",
    "<div align=\"justify\">  \n",
    "    \n",
    "                                     GS = (A − y0) + 0.25μ  \n",
    "</div> \n",
    "<div align=\"justify\"> \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def filter_curves(df = None):\n",
    "    \"\"\"Filter out aberrant curves.\n",
    "    :param df: pandas DataFrame with time-series data.\n",
    "    :return: clean DataFrame with growth scores.\"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    clean = pd.DataFrame()\n",
    "    for name, well in df.groupby('Well'):\n",
    "        well = well.copy().sort_values(['Time']).reset_index()\n",
    "        \n",
    "        # if there is big sudden drop \n",
    "        if (well['grate'].min() < -0.2) and (well['grate'].idxmin() > 4): #0.1\n",
    "            print(name, well['grate'].min())\n",
    "            well['Result'] = 'Invalid_sample'\n",
    "        \n",
    "        # if the curve started at high value\n",
    "        elif well['OD'].values[0] >  0.2:\n",
    "            print(name)\n",
    "            well['Result'] = 'Invalid_sample'\n",
    "        else:\n",
    "            well['Result'] = well['Status']\n",
    "\n",
    "        clean = clean.append(well)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\"> This function filters out aberrant (broken) growth curves from the experiment if the curve starts at unreasonable high value or if the curve shows sudden drops.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dose-response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def ll4(x,b,c,d,e):\n",
    "    \"\"\"Fitting dose-response function - LM equation, LL.4 function (4-parameter sigmoidal function).\n",
    "     - b: hill slope\n",
    "     - c: min response\n",
    "     - d: max response\n",
    "     - e: EC50\"\"\"\n",
    "    import numpy as np\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    return(c+(d-c)/(1+np.exp(b*(np.log(x)-np.log(e)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def inv_log(x = None):\n",
    "    \"\"\"Inverse log calculator\"\"\"\n",
    "    return ((10**-x)/(1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def pDose(x = None): \n",
    "    \"\"\"Helper function, used to compute log transformed concentrations.\"\"\"\n",
    "    import numpy as np\n",
    "    return(-np.log10(1e-6*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def dose_response(df = None, y_label = 'Response', path = None):\n",
    "    \"\"\"Dose response function. The input DataFrame should contain columns 'Compound_id', 'Dose', 'Response'. \n",
    "    The DataFrame shouldn't contain NAN values or dose 0, which will result in infinity at logDose.\n",
    "    The fitting function is a LL.4 function (4-parameter sigmoidal function) with\n",
    "     - b: hill slope\n",
    "     - c: min response\n",
    "     - d: max response\n",
    "     - e: EC50\n",
    "    :param df: pandas DataFrame for plotting.  \n",
    "    :param y_label: name for y-axis.\n",
    "    :param path: path to the output folder to save the results, optional.\n",
    "    :return: DataFrame with Dose Response fitting results.\"\"\"     \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import scipy.optimize as opt\n",
    "    from scipy.stats.stats import pearsonr\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.colors as colors\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    sns.set(context = 'notebook', style = 'white', palette = 'dark')\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    pDose = lambda x:-np.log10(1e-6*x)\n",
    "    ll4 = lambda x, b, c, d, e:(c+(d-c)/(1+np.exp(b*(np.log(x)-np.log(e)))))    \n",
    "    df = df[['Compound_id', 'Dose', 'Response']].copy()\n",
    "    df = df[(df != 0).all(1)]  # drop zero values\n",
    "    df['logDose'] = pDose(df.Dose.astype(float)) # calculate logDose\n",
    "    df_mean = df.groupby(['Compound_id','Dose'], as_index = False).mean() # calculate response mean values\n",
    "    df_mean['std'] = list(df.groupby(['Compound_id','Dose']).std()['Response'].values) # calculate response std         \n",
    "    \n",
    "    fitData = pd.DataFrame()\n",
    "    for name, group in df_mean.groupby(['Compound_id']): # group data by compounds\n",
    "        print(name)   \n",
    "    # fitting curve\n",
    "        try:     \n",
    "                fitCoefs, covMatrix = opt.curve_fit(ll4, group.Dose, group.Response, method = 'lm')\n",
    "                residuals = group.Response - group.Dose.apply(lambda x: ll4(x,*fitCoefs))\n",
    "                curFit = dict(zip(['b','c','d','e'], fitCoefs))\n",
    "                curFit['Compound_id'], curFit['residuals'] = name, sum(residuals**2)\n",
    "                predicted = group.Dose.apply(lambda x: ll4(x,*fitCoefs))\n",
    "                curFit['r_squared'] = pearsonr(group.Response, predicted)[0]**2\n",
    "                curFit['N'] =  int(group.shape[0])\n",
    "                fitData = fitData.append(curFit, ignore_index = True)\n",
    "                EC50_response = ll4(curFit['e'],*[curFit[i] for i in ['b','c','d','e']])\n",
    "\n",
    "                # plot data \n",
    "                raw = df[df.Compound_id == name]\n",
    "                refDose = np.linspace(min(raw.Dose)*0.55, max(raw.Dose)*1.6, 256)\n",
    "                g2 = sns.lmplot('logDose', 'Response', data = group,  fit_reg = False, legend = False, height=6)\n",
    "                g2.map(plt.errorbar, 'logDose', 'Response',yerr = group['std'], fmt='o')\n",
    "                axes = plt.gca()\n",
    "                axes.invert_xaxis()\n",
    "                plt.plot([pDose(i) for i in refDose],[ll4(i,*[curFit[i] for i in ['b','c','d','e']]) for i in refDose])\n",
    "                locs, labels = plt.xticks()\n",
    "                g2.set_xticklabels([round(inv_log(l), 1) for l in locs]) # inverse log for xticks\n",
    "                plt.xlabel('Dose (um)')\n",
    "                plt.ylabel(y_label)\n",
    "                plt.title(name)\n",
    "                \n",
    "                #plot EC_50_label \n",
    "                ymin, ymax = axes.get_ylim()\n",
    "                xmin, xmax = axes.get_xlim()\n",
    "                plt.plot([xmin, pDose(curFit['e'])], [EC50_response, EC50_response], color = 'navy', linestyle = '--', lw = 0.7)\n",
    "                plt.plot([pDose(curFit['e']), pDose(curFit['e'])], [ymin, EC50_response], color = 'navy', linestyle = '--', lw = 0.7)\n",
    "                plt.show()\n",
    "                \n",
    "                if path:\n",
    "                    g2.savefig(path +'//' + name +'_dr_fit.png', bbox_inches='tight', dpi=600)\n",
    "                \n",
    "                plt.close()\n",
    "\n",
    "        except Exception as e:\n",
    "                print('Fitting curve failed:')\n",
    "                print(e)\n",
    "    if not fitData.empty: \n",
    "        fitData = fitData.set_index('Compound_id') # .round(2)\n",
    "        fitData['N'] = fitData.N.astype(int)\n",
    "        fitData.rename(columns = {'b': 'hill slope', 'c': 'min response', 'd': 'max response', 'e': 'EC50'}, inplace = True)\n",
    "        return fitData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def plot_dr_viability(data = None, y_label = 'Response', path = None):\n",
    "    \"\"\"Plots response vs viability. The DataFrame should contain columns ['Compound', 'Dose','logDose', 'Viability', 'Response'] (at least).\"\"\"\n",
    "    import pandas as pd\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.colors as colors\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    sns.set(context = 'notebook', style = 'white', palette = 'dark')\n",
    "    \n",
    "    df = data[['Compound_id', 'Dose','logDose', 'Viability', 'Response']]\n",
    "    df = df[(df != 0).all(1)]  # drop zero values\n",
    "    df_mean = df.groupby(['Compound_id','Dose'], as_index = False).mean() # calculate response mean values\n",
    "    df_mean['resp_std'] = list(df.groupby(['Compound_id','Dose']).std()['Response'].values) # calculate response std\n",
    "    df_mean['via_std'] = list(df.groupby(['Compound_id','Dose']).std()['Viability'].values) # calculate viability std\n",
    "\n",
    "    for name, group in  df_mean.groupby('Compound_id'):  # group data by compounds\n",
    "        group = group.sort_values('Dose')\n",
    "        error_resp, error_via  = group['resp_std'], group['via_std']\n",
    "          \n",
    "        fig, ax1 = plt.subplots(figsize = (6,6))  \n",
    "        plt.title(name, fontsize = 16)\n",
    "\n",
    "        plot1 = ax1.plot(group['logDose'], group['Response'], 'b', label = 'Response')\n",
    "        ax1.set_xlim(max(group['logDose'])*1.07, min(group['logDose'])*0.9)\n",
    "        ax1.set_ylabel(y_label, fontsize = 16)\n",
    "        ax1.set_ylim(0, df_mean['Response'].max()*1.2)\n",
    "        ax1.errorbar(group['logDose'], group['Response'],yerr = error_resp, fmt ='o', color ='b', ecolor = 'lightblue')\n",
    "\n",
    "        ax2 = ax1.twinx()\n",
    "        plot2 = ax2.plot(group['logDose'], group['Viability'], 'g', label = 'Viability')\n",
    "        ax2.set_xlim(max(group['logDose'])*1.07, min(group['logDose'])*0.9)\n",
    "        ax2.set_ylabel('Viability', fontsize = 16)\n",
    "        ax2.set_ylim(0, 120)\n",
    "        ax2.errorbar(group['logDose'], group['Viability'],yerr=error_via, fmt='o', color='g', ecolor='lightgreen')\n",
    "        ax1.set_xlabel('Dose, um', fontsize = 16)\n",
    "\n",
    "        # create legend\n",
    "        lines = plot1 + plot2\n",
    "        ax1.legend(lines, [l.get_label() for l in lines])\n",
    "        locs, labels = plt.xticks()\n",
    "        new_labels =[]\n",
    "        for loc in locs:\n",
    "            inv_log = lambda x:((10**-x)/(1e-6)) # inverse log calculator to set xticks\n",
    "            inv_x = round(inv_log(loc), 1)\n",
    "            new_labels.append(inv_x)\n",
    "        ax1.set_xticklabels(new_labels) \n",
    "        if path:\n",
    "            plt.savefig(path +'//' + name +'_raw_viability.png', bbox_inches='tight', dpi=600)\n",
    "        plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def prune_compound(df, threshold = -0.15):\n",
    "    \"\"\"This function takes DataFrame of one-compound dose-response data, find maximum activity, \n",
    "    and drops rows starting from treshold-defined reduction of Response. The default value for threshold = -0.15, \n",
    "   it drops rows starting from 15% reduction of Response. The input DataFrame should contain columns \n",
    "   'Compound_id', 'Dose', 'Response'.\"\"\"\n",
    "    \n",
    "    prunned = pd.DataFrame()\n",
    "    df = df.sort_values('Dose')\n",
    "    curr_max = 0.0000001\n",
    "    groups = df.groupby('Dose')\n",
    "    for name, group in groups:\n",
    "        percent_change = (group['Response'].mean()/curr_max)-1\n",
    "        if group['Response'].mean() > curr_max:\n",
    "            curr_max = group['Response'].mean()\n",
    "        if percent_change > threshold:\n",
    "            prunned = prunned.append(group)\n",
    "    return(prunned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def plot_polynomial(df = None, y_label = 'Response', degree = 2, path = None):\n",
    "    \"\"\"Plot polynomial fit.\n",
    "    :param df: pandas DataFrame for plotting.  \n",
    "    :param y_label: name for y-axis.\n",
    "    :param degree: degree of the polynomial fit.\n",
    "    :param path: path to the output folder to save the results, optional.\n",
    "    :return: None.\"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.colors as colors\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    try:\n",
    "        df = df[['Compound_id', 'Dose', 'Response']]\n",
    "        df = df[(df != 0).all(1)]  # drop zero values\n",
    "        df['logDose'] = pDose(df['Dose'].astype(float))\n",
    "    except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    # plot response\n",
    "    for name, group in df.groupby('Compound_id'):\n",
    "        mean_group = group.groupby(['Dose'], as_index = False).mean()\n",
    "        g = sns.lmplot('logDose', 'Response', data = mean_group,  fit_reg = False, legend = False, height=6)\n",
    "        g.map(plt.errorbar, 'logDose', 'Response',yerr = list(group.groupby(['Dose']).std()['Response'].values), fmt='o')\n",
    "        plt.xlim(max(group['logDose'])*1.1, min(group['logDose'])*0.9)   \n",
    "        locs, labels = plt.xticks() \n",
    "        g.set_xticklabels([round(inv_log(l), 1) for l in locs]) # inverse log for xticks       \n",
    "        plt.xlabel('Dose (um)')\n",
    "        plt.ylabel(y_label)\n",
    "        plt.title(name)\n",
    "        \n",
    "        # plot polynomial_fit\n",
    "        try:\n",
    "            X  = np.asarray(group['logDose'].values)\n",
    "            Y  = np.asarray(group['Response'].values)\n",
    "            p = np.poly1d(np.polyfit(X,Y,degree))\n",
    "            polyDose = np.linspace(min(group['logDose'])*0.98, max(group['logDose'])*1.02, 256)\n",
    "            plt.plot(polyDose, p(polyDose), color='Navy')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print('Polynomial fit failed:')\n",
    "            print(e)\n",
    "        plt.show()\n",
    "        if path:\n",
    "            g.savefig(path +'//' + name +'_polynomial.png', bbox_inches='tight', dpi=600)   \n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def plot_treatments(df = None, x = None, y = None, column = None, kind = None, ylabel = None, \n",
    "                    palette = None, height = None, aspect = None, save_as = None, path = None):\n",
    "    \"\"\"Creates plot by treatments. If your data has different treatments, set column = 'Treatment'. \n",
    "    :param df: pandas DataFrame for plotting. \n",
    "    :param x, y: names of variables in data, optional.\n",
    "    :param column, kind, ylabel, palette, high, aspect: These features are seaborn.boxplot features.  \n",
    "    :param save_as: filename to save the resulting figure, optional.\n",
    "    :param path: path to the output folder to save the resulting figure, optional.\n",
    "    :return: None.\"\"\"\n",
    "    import pandas as pd\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.colors as colors\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    plot_data = df[df['Status'] != 'Reference'] #filter out the Reference wells\n",
    "    g = sns.catplot(x = x, y = y, data = plot_data, col = column, kind = kind, palette = palette,\n",
    "                    height = height, aspect = aspect, margin_titles = False)\n",
    "    axes = g.axes.flatten()\n",
    "    axes[0].set_ylabel(ylabel)\n",
    "    g.set_xticklabels(rotation = 90)\n",
    "    if path:\n",
    "        plt.savefig(path + '//' + save_as, bbox_inches = 'tight', dpi = 600)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def plot_curve_raw(df = None, x = None, y = None, units = None, hue = None, hue_order = None, xlabel = None,\n",
    "                   ylabel = None, xlimit = None, palette = None, save_as = None, path = None):\n",
    "    \"\"\"Plots raw kinetic curves.  \n",
    "    :param df: pandas DataFrame for plotting. \n",
    "    :param x, y: names of variables in data.\n",
    "    :param units, hue, hue_order, xlabel, ylabel, xlimit, palette, high, aspect: These features are seaborn.boxplot features.  \n",
    "    :param save_as: filename to save the resulting figure, optional.\n",
    "    :param path: path to the output folder to save the resulting figure, optional.\n",
    "    :return: None.\"\"\"\n",
    "    import pandas as pd\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.colors as colors\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    ax = sns.lineplot(data = df, x = x, y = y, units = units, hue = hue, hue_order = hue_order, palette = palette, estimator = None)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlim(0, xlimit)\n",
    "    fig = ax.get_figure()\n",
    "    fig.set_size_inches(10, 7)\n",
    "    \n",
    "    if path:\n",
    "        plt.savefig(path + '//' + save_as, bbox_inches = 'tight', dpi = 600)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def plot_curve_mean(df = None, x = None, y = None, hue = None, hue_order = None, xlabel = None, ylabel = None,\n",
    "                    xlimit = None, palette = None, save_as = None, path = None):\n",
    "    \"\"\"Plots mean kinetic curves. \n",
    "    :param df: pandas DataFrame for plotting.  \n",
    "    :param x, y: names of variables in data.\n",
    "    :param hue, hue_order, xlabel, ylabel, xlimit, palette, high, aspect: These features are seaborn.boxplot features.  \n",
    "    :param save_as: filename to save the resulting figure, optional.\n",
    "    :param path: path to the output folder to save the resulting figure, optional.\n",
    "    :return: None.\n",
    "    \"\"\" \n",
    "    import pandas as pd\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.colors as colors\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    ax = sns.lineplot(data = df, x = x, y = y, hue = hue, hue_order = hue_order, palette = palette)\n",
    "    sns.despine()\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlim(0, xlimit)\n",
    "    fig = ax.get_figure()\n",
    "    fig.set_size_inches(10, 7)\n",
    "    if path:\n",
    "         plt.savefig(path + '//' + save_as, bbox_inches = 'tight', dpi = 600)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def pointplot_plate(df = None, x = None, y = None, hue = None, hue_order = None, threshold = None, ylabel = None,\n",
    "                    palette = None,  save_as = None, path  = None):\n",
    "    \"\"\"Creates point plot for the experiment.\n",
    "    :param df: pandas DataFrame for plotting.  \n",
    "    :param x, y: names of variables in data.\n",
    "    :param hue, hue_order, ylabel, xlimit, palette: These features are seaborn.boxplot features. \n",
    "    :param threshold: threshold for hit identification.\n",
    "    :param save_as: filename to save the resulting figure, optional.\n",
    "    :param path: path to the output folder to save the resulting figure, optional.\n",
    "    :return: None.\"\"\"\n",
    "    import pandas as pd\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.colors as colors\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    g = sns.catplot(data = df, x = x, y = y, hue = hue, height = 6, aspect = 2.5, margin_titles = False,\n",
    "                   palette = palette, hue_order = hue_order)\n",
    "    if threshold:\n",
    "        plt.plot([0, len(df.Well.unique())], [threshold, threshold],'r-')\n",
    "        plt.plot([0, len(df.Well.unique())], [-threshold, -threshold],'r-')\n",
    "    \n",
    "    g.set_xticklabels([])\n",
    "    plt.ylabel(ylabel)\n",
    "    g.despine()\n",
    "    if path:\n",
    "         g.savefig(path +'//' + save_as, bbox_inches = 'tight', dpi = 600)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def df_to_table(df = None, slide = None, left = None, top = None, width = None, height = None, colnames = None):\n",
    "    \"\"\"Converts a Pandas DataFrame to a PowerPoint table on the given slide of a PowerPoint presentation.\n",
    "    The table is a standard Powerpoint table, and can easily be modified with the Powerpoint tools (resizing columns, changing formatting etc).\n",
    "    Source:  https://github.com/robintw/PandasToPowerpoint/blob/master/PandasToPowerpoint.py\n",
    "    :param df: pandas DataFrame with the data. \n",
    "    :param slide: slide object from the python-pptx library containing the slide on which you want the table to appear\n",
    "    :param left, top, right, width, height, colnames: These parameters are python-pptx parameters.\n",
    "    :return: Powerpoint table.\n",
    "     \"\"\"\n",
    "    import pandas as pd\n",
    "    from pptx import Presentation\n",
    "    from pptx.util import Inches, Pt\n",
    "    \n",
    "    rows, cols = df.shape\n",
    "    res = slide.shapes.add_table(rows + 1, cols, left, top, width, height)\n",
    "\n",
    "    if colnames is None:\n",
    "        colnames = list(df.columns)\n",
    "        colnames[0] = 'idx'\n",
    "\n",
    "    # Insert the column names\n",
    "    for col_index, col_name in enumerate(colnames):\n",
    "        # Column names can be tuples\n",
    "        if not isinstance(col_name, str):\n",
    "            col_name = ' '.join(col_name)\n",
    "        res.table.cell(0, col_index).text = col_name\n",
    "        paragraph = res.table.cell(0, col_index).text_frame.paragraphs[0]\n",
    "        paragraph.font.size = Pt(9)\n",
    "\n",
    "    #m = df.as_matrix()\n",
    "    m = df.values\n",
    "\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            val = m[row, col]\n",
    "            text = str(val)\n",
    "            res.table.cell(row + 1, col).text = text\n",
    "            paragraph = res.table.cell(row + 1, col).text_frame.paragraphs[0]\n",
    "            paragraph.font.size = Pt(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def create_presentation(path = None):\n",
    "    \"\"\"Creates ppt report from files in the specified folder. \n",
    "    Reads template ppt file and files in the input folder, adds all pictures and tables with \n",
    "    size less than 30 rows from input folder.\n",
    "    :param path: path to the output folder to save the results.\n",
    "    :return: None.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    from datetime import date\n",
    "    from pptx import Presentation\n",
    "    from pptx.util import Inches, Pt\n",
    "\n",
    "    report = Presentation('hts_data//templates//ppt_template.pptx')\n",
    "    slide = report.slides.add_slide(report.slide_layouts[6])  \n",
    "    #pic = slide.shapes.add_picture('hts_data//templates//logo.png', left = Inches(3), top = Inches(0.2))\n",
    "    subtitle = slide.shapes.add_textbox(left = Inches(5.), top = Inches(3.5), width = Inches(3), height = Inches(0.5),).text_frame\n",
    "    p = subtitle.paragraphs[0]\n",
    "    run = p.add_run() \n",
    "    run.text = 'Technical Report\\nGenerated on {:%m-%d-%Y}'.format(date.today())\n",
    "    font = run.font\n",
    "    font.size = Pt(18) \n",
    "    files_list = os.listdir(path)\n",
    "    for myfile in files_list:\n",
    "        if 'heatmap.png' in myfile:\n",
    "            slide = report.slides.add_slide(report.slide_layouts[6])\n",
    "            left = top = Inches(0.7)\n",
    "            height = Inches(6)\n",
    "            pic = slide.shapes.add_picture(path + '//' + myfile, left, top, width = Inches(5.8), height= Inches(4))         \n",
    "        elif '.png' in myfile and 'heatmap.png' not in myfile:\n",
    "            slide = report.slides.add_slide(report.slide_layouts[6])\n",
    "            subtitle = slide.shapes.add_textbox(left = Inches(0.5), top = Inches(0.3), width = Inches(2), height = Inches(0.5)).text_frame       \n",
    "            subtitle.text = myfile\n",
    "            left = top = Inches(0.7)\n",
    "            pic = slide.shapes.add_picture(path +'//' + myfile, left, top = Inches(0.8), height= Inches(6))  \n",
    "            left = Inches(0.7)\n",
    "        elif 'csv' in myfile:\n",
    "            try:\n",
    "                table = pd.read_csv(path +'//' + myfile)\n",
    "                if table.shape[0]<30:  \n",
    "                    slide = report.slides.add_slide(report.slide_layouts[6])\n",
    "                    subtitle = slide.shapes.add_textbox(left = Inches(0.5), top = Inches(0.3), width = Inches(2), height = Inches(0.5)).text_frame\n",
    "                    subtitle.text = myfile\n",
    "                    slide_table = df_to_table(table, slide, left = Inches(0.3), top = Inches(1), width = Inches(12.5), height = Inches(0.3)) \n",
    "                left = Inches(0.7)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted index.ipynb.\n",
      "Converted simplydrug.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "# export all modules directly from a notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
