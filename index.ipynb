{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from simplydrug.core import *\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to simplydrug\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\">  To advance scientific communication and integrative drug discovery, we developed a set of open-source based analysis workflows. These workflows describe the early stages of biological assay development and high throughput screening and provide a hands-on introduction to Drug Discovery for everybody with basic knowledge of biology, python programming, or data science. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left; margin-right:700px\"  width=\"550\" src=\"hts_notebooks/hts_images/bcdd.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebooks are built in a sequence and gradually introduce concepts of experimental design, QC, and data analysis of different biological assays.\n",
    " \n",
    " * [__01a_enzyme_kinetics__](https://github.com/disc04/simplydrug/blob/master/hts_notebooks/01a_enzyme_kinetics.ipynb)      \n",
    "Topics: enzyme kinetics, enzyme assays, fluorometry, assay variability and confidence intervals, Z-factor, Z-score based normalization, plate heatmap, hit extraction, molecule visualization, importing molecule bioactivity data.\n",
    " \n",
    " \n",
    " * [__01b_enzyme_kinetics_in_chain__ ](https://github.com/disc04/simplydrug/blob/master/hts_notebooks/01b_enzyme_kinetics_chain.ipynb)      \n",
    "Topics: Running enzymatic assay for a number of plates, generating screen hit matrix, plot for all the plates in the screen.     \n",
    "\n",
    "\n",
    " \n",
    " * [__02a_ion_channel_development__ ](https://github.com/disc04/simplydrug/blob/master/hts_notebooks/02a_ion_channel_development.ipynb)             \n",
    "Topics: Introduction to ion channels and assay development, ion flux assay normalization, ion channel kinetics time-series.\n",
    "\n",
    "\n",
    " \n",
    " * [__02b_ion_channel_cherry_picking__](https://github.com/disc04/simplydrug/blob/master/hts_notebooks/02b_ion_channel_cherry_picking.ipynb)         \n",
    " Topics: Calcium influx assay, cherry picking, percent of activation or inhibition.      \n",
    " \n",
    " \n",
    " \n",
    " * [__02c_ion_channel_dose_response__](https://github.com/disc04/simplydrug/blob/master/hts_notebooks/02c_ion_channel_dose_response.ipynb)       \n",
    "Topics: Introduction to dose-response, Hill equation.   \n",
    "   \n",
    " \n",
    " * [__03a_yeast_growth_screen__](https://github.com/disc04/simplydrug/blob/master/hts_notebooks/03a_yeast_growth_screen.ipynb)     \n",
    " Topics: Running yeast growth assay, growth curve, growth score, filtering out aberrant curves.\n",
    " \n",
    " \n",
    " * [__03b_yeast_growth_in_chain__](https://github.com/disc04/simplydrug/blob/master/hts_notebooks/03b_yeast_growth_in_chain.ipynb)     \n",
    " Topics: Running yeast growth assay for a number of plates, filtering, generating screen hit matrix, plotting all the plates in the screen.     \n",
    "  \n",
    "   \n",
    " * [__03c_yeast_cherry_picking__](https://github.com/disc04/simplydrug/blob/master/hts_notebooks/03c_yeast_cherry_picking.ipynb)         \n",
    "Topics: Running yeast growth assay with different doses of the compounds. Generation of automatic ppt report.\n",
    "\n",
    "  \n",
    " * [__04a_imaging_screen__](https://github.com/disc04/simplydrug/blob/master/hts_notebooks/04a_imaging_screen.ipynb)      \n",
    " Topics: High-content screening and image analysis, reporter system, cell viability, systematic errors detection and correction. \n",
    " \n",
    " \n",
    " * [__4b_imaging_assay_development__](https://github.com/disc04/blob/master/simplydrug/hts_notebooks/4b_imaging_assay_development.ipynb)  \n",
    " Topics: Exploration data anslysdis, PCA, Batch effect.\n",
    " \n",
    " \n",
    " \n",
    " * [__04c_imaging_dose_response__ ](https://github.com/disc04/simplydrug/blob/master/hts_notebooks/04c_imaging_dose_response.ipynb)    \n",
    " Topics: Activity versus viability, fitting dose-response for imaging data. \n",
    " \n",
    " \n",
    " * [__05_xtt_assay__](https://github.com/disc04/simplydrug/blob/master/hts_notebooks/05_xtt_assay.ipynb)    \n",
    "Dose-response assay for compound toxicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several options:\n",
    "\n",
    "1. Run the notebooks from Binder    \n",
    "\n",
    "[![Binder](https://img.shields.io/badge/Binder%20Launch:-simplydrug-blue.svg?colorA=&logo=data:image/png;base64,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)](https://mybinder.org/v2/gh/disc04/simplydrug/master)\n",
    "\n",
    "2. pip install simplydrug     \n",
    "\n",
    "3. Clone this repository: git clone https://github.com/disc04/simplydrug\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "The codebase relies on the following dependencies (tested version provided in parentheses):\n",
    "\n",
    " - python (3.6.1)\n",
    " - pubchempy (1.0.4)\n",
    " - scipy (1.4.1)\n",
    " - seaborn (0.10.0)\n",
    " - python-pptx (0.6.18)\n",
    " - wget(3.2)\n",
    " - xlrd (1.2.0)\n",
    " - rdkit (2019.09.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\"> In each experiment, first, we merge numerical data coming from equipment with the plate layout (descriptors). We describe the experimental design in a layout excel file, and the names of the excel sheets become the names of the columns in a final data table. Each excel sheet contains a table with dimensions of the experiment plate (usually 96 or 384-well plates) and represents some aspect of the layout  -  well ID, treatment, cell density, compound ID, compound concentration, etc.</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\"> The layout file must contain sheets named  'Well' and 'Status'. The 'Well' table lists well IDs, and the 'Status' can contain either 'Sample', 'Positive' or 'Negative' control, or 'Reference' values. 'Reference' wells are excluded from calculations. The function add_layout merges measurements and layout by the 'Well' column.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import simplydrug.core as sd\n",
    "\n",
    "data = pd.DataFrame(pd.ExcelFile('hts_notebooks//hts_data//enzyme_kinetics_data1.xlsx').parse(0))[['Well','0s','120s','240s', '360s']]\n",
    "layout_path = 'hts_notebooks//hts_data//enzyme_kinetics_layout.xlsx'\n",
    "chem_path = 'hts_notebooks//hts_data//compounds//example_chemicals.csv'\n",
    "chem_plate = 'ex_plate1'\n",
    "\n",
    "results = sd.add_layout(data, layout_path, chem_path = chem_path, chem_plate = chem_plate)\n",
    "display(results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left; margin-right:700px\"  width=\"950\" src=\"hts_notebooks/hts_images/index_df.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check our 384 well plate for systematic errors, we often use heatmap representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.hts_heatmap(df = results, layout_path = layout_path, features = ['120s'], path = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left; margin-right:700px\"  width=\"550\" src=\"hts_notebooks/hts_images/index_heatmap.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\"> In this plate, most of the readings across the plate are close to the plate average, and four wells with high readings probably represent our hit compounds.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def exception_handler(func):\n",
    "    \"\"\"Exception handler helper function.\n",
    "    \"\"\"   \n",
    "    def wrapper_func(*args, **kwargs): \n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            print(f'{func.__name__} exception: ')\n",
    "            print(e)\n",
    "            return None\n",
    "    return wrapper_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def add_layout(df = None, layout_path = None, chem_path = None, chem_plate = None): \n",
    "    \"\"\"Add_layout function updates DataFrame containing measurements with descriptors columns taken from plate layout excel file.  \n",
    "    Sheet names in the layout file are translated to column names in the updated DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    layout = pd.DataFrame()\n",
    "    for sheet in pd.ExcelFile(layout_path).sheet_names:   # create columns from excel file\n",
    "        layout[sheet] = np.asarray(pd.ExcelFile(layout_path).parse(sheet)).reshape(-1)\n",
    "        print('Added ', sheet)\n",
    "   \n",
    "    if chem_path and chem_plate: # add compound IDs\n",
    "        compounds = pd.read_csv(chem_path, low_memory = False)\n",
    "        layout = pd.merge(layout, compounds[compounds.Plate == chem_plate], how = 'left', on = 'Well')\n",
    "        print('Added compounds: ',chem_plate,'\\n') \n",
    "\n",
    "    else:\n",
    "        print('Chemical library not requested')\n",
    "        \n",
    "    output = pd.merge(df, layout, how = 'left', on = 'Well') \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\">Add_layout function takes DataFrame, the path to layout excel file, the path to chemical library and plate name, and returns an updated DataFrame with added layout columns. We use a layout excel file to describe the experimental design, and the names of the excel sheets become the names of the columns in a final data table. Each excel sheet contains a table with dimensions of the experiment plate (usually 96 or 384-well plates) and represents some aspect of the layout - well ID, treatment, cell density, compound ID, compound concentration, etc.\n",
    "The layout file must contain sheets named 'Well' and 'Status'. The 'Well' table lists well IDs, and the 'Status' can contain either 'Sample', 'Positive' or 'Negative' control, or 'Reference' values. 'Reference' wells are excluded from calculations. The function add_layout merges measurements and layout by the 'Well' column.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left; margin-right:700px\"  width=\"850\" src=\"hts_notebooks/hts_images/layout.png\" > "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\"> Next, we need to import compound ids from chemical library. There are two options. We can fill compound ids manually in the layout excel, or we can give to the function the plate name from defined library. In this module, we will use example_chemicals.csv file located in hts_data/compounds. The name of the library is 'example_library', it contains random compounds divided into 3 plates: 'ex_plate1', 'ex_plate2', and 'ex_plate3'\n",
    "For example, to load compounds from plate 3 of the library, we will pass to the function chem_path = 'hts_data//compounds//example_chemicals.csv, and chem_plate = 'ex_plate3'.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example of chemical library file:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left; margin-right:700px\"  width=\"750\" src= \"hts_notebooks/hts_images/chemlib.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def order_wells(x = None): \n",
    "    import re\n",
    "    \"\"\"Orders wells as they appear in the plate. For example, converts ['A10', 'A11', 'A12', 'A1', 'A2'] to ['A1', 'A2', 'A10', 'A11', 'A12']. \n",
    "    \"\"\"\n",
    "    convert = lambda text: int(text) if text.isdigit() else text \n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ]\n",
    "    return sorted(x, key = alphanum_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def hts_heatmap(df = None, layout_path = None, features = None, save_as = None, path = None):\n",
    "    \"\"\"Takes DataFrame, list of features, a path to layout file, and the output folder and creates a plate heatmap for the input features.\n",
    "    \"\"\"\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.colors as colors\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    # merge data with well names and status\n",
    "    layout = pd.DataFrame({'Well':np.asarray(pd.ExcelFile(layout_path).parse('Well')).reshape(-1), \n",
    "                      'Status': np.asarray(pd.ExcelFile(layout_path).parse('Status')).reshape(-1)})\n",
    "    data = pd.merge(layout, df.groupby('Well').mean(), how = 'left', on ='Well').set_index('Well', drop = False)\n",
    "    samples = data[data['Status'] == 'Sample'].dropna() \n",
    "    \n",
    "    # define plate format\n",
    "    if data.shape[0] == 384: \n",
    "        plate_reshape = (16,24) # number of rows, number of columns for 384\n",
    "        yticks=['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P']\n",
    "        xticks=['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22', '23','24']\n",
    "    elif data.shape[0] == 96:\n",
    "        plate_reshape = (8,12) # number of rows, number of columns for 96\n",
    "        yticks=['A','B','C','D','E','F','G','H']\n",
    "        xticks=['1','2','3','4','5','6','7','8','9','10','11','12']         \n",
    "    else: \n",
    "        print('Unknown plate format - cannot generate the heatmaps')\n",
    "        \n",
    "    # order wells properly\n",
    "    ordered_data =  pd.DataFrame()\n",
    "    for well in order_wells(data.Well):\n",
    "        ordered_data = ordered_data.append(data.loc[well,:])  \n",
    "        \n",
    "    # build heatmap for each feature\n",
    "    for f in features:        \n",
    "        plate_view = ordered_data[f].values.reshape(plate_reshape) \n",
    "        plate_view[np.isnan(plate_view)] = samples[f].mean() # fill missing values with sample mean value\n",
    "        vmin = samples[f].mean() - 3*(samples[f].std()) # min value for the heatmap\n",
    "        vmax = samples[f].mean() + 3*(samples[f].std()) # min value for the heatmap\n",
    "        \n",
    "        # plot\n",
    "        ax = sns.heatmap(plate_view, vmin, vmax, center = samples[f].mean(), yticklabels = yticks, xticklabels = xticks, cmap = 'RdBu_r')\n",
    "        ax.set_yticklabels(yticks, rotation = 0) \n",
    "        ax.set_xticklabels(xticks,rotation = 0)\n",
    "        ax.set_title(f + ' \\n')\n",
    "        fig = ax.get_figure()\n",
    "        fig.set_size_inches(7, 4)\n",
    "        if path:\n",
    "            plt.savefig(path + '//' + f + save_as, bbox_inches = 'tight', dpi = 600)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def sum_statistics(df = None, feature = None):\n",
    "    \"\"\"Takes DataFrame and calculates summary statistics for the experiment. The data must contain the 'Status' column, defining each row as 'Sample', 'Positive' or 'Negative' control, or 'Reference'.  'Reference' wells are excluded from the analysis.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from scipy import stats\n",
    "    \n",
    "    st = None\n",
    "    df = df[df.Status != 'Reference'][[feature, 'Status']]\n",
    "    st = df.groupby(['Status']).agg([np.size, np.mean, np.std, np.var])\n",
    "    st.columns = st.columns.droplevel()\n",
    "    st['Feature'] = feature  \n",
    "    \n",
    "    if 'Positive' in df['Status'].unique() and 'Negative' in df['Status'].unique(): \n",
    "        st['Z_factor'] = 1 - 3*(st.at['Positive','std'] + st.at['Negative','std'])/abs(st.at['Positive','mean'] - st.at['Negative','mean'])  \n",
    "        st['SB'] = st.at['Positive','mean']/st.at['Negative','mean']\n",
    "        st = st.reset_index()[['Feature', 'Status', 'size', 'mean', 'std', 'var', 'Z_factor', 'SB' ]]\n",
    "    else:\n",
    "        print('sum_statistics: Failed calculate Z factor. Positive or Negative control is missing.')\n",
    "        st = st.reset_index()[['Feature', 'Status', 'size', 'mean', 'std', 'var']]\n",
    "        pass\n",
    "    return st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Z-score normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def normalize_z(df = None, feature = None):\n",
    "    \"\"\"Takes DataFrame with measurements and feature name and adds a column with normalized values of the feature.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    mean = df[df['Status'] == 'Sample'][[feature]].mean()\n",
    "    std = df[df['Status'] == 'Sample'][[feature]].std()  \n",
    "    df[feature + '_norm'] =  df[feature].apply(lambda x:(x - mean)/std)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def histogram_feature(df = None, feature = None, save_as = None, path = None):\n",
    "    \"\"\"Creates histogram of the input feature.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.colors as colors\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    sns.distplot(df[feature].values)\n",
    "    plt.plot([-2, -2], [0, 0.5], color = 'r', linestyle = '--', lw = 1.7)\n",
    "    plt.plot([2, 2], [0, 0.5], color = 'r', linestyle = '--', lw = 1.7)\n",
    "    if path:\n",
    "        plt.savefig(path + '//' + save_as, bbox_inches = 'tight', dpi = 600)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Growth score functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def calculate_growth_score(df = None): \n",
    "    \"\"\"Calculates growth scores from time series data. Takes pandas DataFrame with time-series data and returns DataFrame with growth scores.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    df = df.astype(float).sort_values(['Time']) # sort by time\n",
    "    times = df['Time'].values.astype(int)\n",
    "    # create time-series table\n",
    "    ts_data = pd.DataFrame()\n",
    "    for name, data in df.drop(columns = ['Time']).iteritems():\n",
    "        ts_data = ts_data.append(pd.DataFrame({'Well': name, 'Time': times, 'OD': data}))\n",
    "    \n",
    "    # calculate drowth score\n",
    "    score_data = pd.DataFrame()\n",
    "    for name, well in ts_data.groupby('Well'):\n",
    "        well = well.copy()\n",
    "        well['past'] = np.append(well['OD'].values[0], well['OD'].values[:-1])\n",
    "        well['grate'] = (well['OD'] - well['past'])/well['past']\n",
    "        well['gscore'] = (well['OD'].max() - well['OD'].values[0]) + well['grate'].max()*0.25        \n",
    "        score_data = score_data.append(well)\n",
    "        \n",
    "    score_data = score_data.drop(columns = ['past']) \n",
    "    return score_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\"> This function used to calculate Growth Scores from time-series data. The Growth Score is defined by three parameters of the Zwietering (Zwietering et al., 1990) bacterial growth curve - the starting absorbance y0, biomass yield  A, and the maximum growth rate μ:\n",
    "</div>  \n",
    "<div align=\"justify\">  \n",
    "    \n",
    "                                     GS = (A − y0) + 0.25μ  \n",
    "</div> \n",
    "<div align=\"justify\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def filter_curves(df = None):\n",
    "    \"\"\"Filter out aberrant curves.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    clean = pd.DataFrame()\n",
    "    for name, well in df.groupby('Well'):\n",
    "        well = well.copy().sort_values(['Time']).reset_index()\n",
    "        \n",
    "        # if there is big sudden drop \n",
    "        if (well['grate'].min() < -0.2) and (well['grate'].idxmin() > 4): #0.1\n",
    "            print(name, well['grate'].min())\n",
    "            well['Result'] = 'Invalid_sample'\n",
    "        \n",
    "        # if the curve started at high value\n",
    "        elif well['OD'].values[0] >  0.2:\n",
    "            print(name)\n",
    "            well['Result'] = 'Invalid_sample'\n",
    "        else:\n",
    "            well['Result'] = well['Status']\n",
    "\n",
    "        clean = clean.append(well)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\"> This function filters out aberrant (broken) growth curves from the experiment if the curve starts at unreasonable high value or if the curve shows sudden drops.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dose-response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def ll4(x,b,c,d,e):\n",
    "    \"\"\"Dose-response function - LM equation, LL.4 function (4-parameter sigmoidal function).\n",
    "     - b: hill slope\n",
    "     - c: min response\n",
    "     - d: max response\n",
    "     - e: EC50\"\"\"\n",
    "    import numpy as np\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    return(c+(d-c)/(1+np.exp(b*(np.log(x)-np.log(e)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def inv_log(x = None):\n",
    "    \"\"\"Inverse log calculator\"\"\"\n",
    "    return ((10**-x)/(1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def pDose(x = None): \n",
    "    \"\"\"Helper function, used to compute log transformed concentrations.\"\"\"\n",
    "    import numpy as np\n",
    "    return(-np.log10(1e-6*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def dose_response(df = None, y_label = 'Response', path = None):\n",
    "    \"\"\"Dose response function. The input DataFrame should contain columns 'Compound_id', 'Dose', 'Response'. \n",
    "    The DataFrame shouldn't contain NAN values or dose 0, which will result in infinity at logDose.\n",
    "    The fitting function is a LL.4 function (4-parameter sigmoidal function) with\n",
    "     - b: hill slope\n",
    "     - c: min response\n",
    "     - d: max response\n",
    "     - e: EC50\n",
    "     \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import scipy.optimize as opt\n",
    "    from scipy.stats.stats import pearsonr\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.colors as colors\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    sns.set(context = 'notebook', style = 'white', palette = 'dark')\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    pDose = lambda x:-np.log10(1e-6*x)\n",
    "    ll4 = lambda x, b, c, d, e:(c+(d-c)/(1+np.exp(b*(np.log(x)-np.log(e)))))    \n",
    "    df = df[['Compound_id', 'Dose', 'Response']].copy()\n",
    "    df = df[(df != 0).all(1)]  # drop zero values\n",
    "    df['logDose'] = pDose(df.Dose.astype(float)) # calculate logDose\n",
    "    df_mean = df.groupby(['Compound_id','Dose'], as_index = False).mean() # calculate response mean values\n",
    "    df_mean['std'] = list(df.groupby(['Compound_id','Dose']).std()['Response'].values) # calculate response std         \n",
    "    \n",
    "    fitData = pd.DataFrame()\n",
    "    for name, group in df_mean.groupby(['Compound_id']): # group data by compounds\n",
    "        print(name)   \n",
    "    # fitting curve\n",
    "        try:     \n",
    "                fitCoefs, covMatrix = opt.curve_fit(ll4, group.Dose, group.Response, method = 'lm')\n",
    "                residuals = group.Response - group.Dose.apply(lambda x: ll4(x,*fitCoefs))\n",
    "                curFit = dict(zip(['b','c','d','e'], fitCoefs))\n",
    "                curFit['Compound_id'], curFit['residuals'] = name, sum(residuals**2)\n",
    "                predicted = group.Dose.apply(lambda x: ll4(x,*fitCoefs))\n",
    "                curFit['r_squared'] = pearsonr(group.Response, predicted)[0]**2\n",
    "                curFit['N'] =  int(group.shape[0])\n",
    "                fitData = fitData.append(curFit, ignore_index = True)\n",
    "                EC50_response = ll4(curFit['e'],*[curFit[i] for i in ['b','c','d','e']])\n",
    "\n",
    "                # plot data \n",
    "                raw = df[df.Compound_id == name]\n",
    "                refDose = np.linspace(min(raw.Dose)*0.55, max(raw.Dose)*1.6, 256)\n",
    "                g2 = sns.lmplot('logDose', 'Response', data = group,  fit_reg = False, legend = False, height=6)\n",
    "                g2.map(plt.errorbar, 'logDose', 'Response',yerr = group['std'], fmt='o')\n",
    "                axes = plt.gca()\n",
    "                axes.invert_xaxis()\n",
    "                plt.plot([pDose(i) for i in refDose],[ll4(i,*[curFit[i] for i in ['b','c','d','e']]) for i in refDose])\n",
    "                locs, labels = plt.xticks()\n",
    "                g2.set_xticklabels([round(inv_log(l), 1) for l in locs]) # inverse log for xticks\n",
    "                plt.xlabel('Dose (um)')\n",
    "                plt.ylabel(y_label)\n",
    "                plt.title(name)\n",
    "                \n",
    "                #plot EC_50_label \n",
    "                ymin, ymax = axes.get_ylim()\n",
    "                xmin, xmax = axes.get_xlim()\n",
    "                plt.plot([xmin, pDose(curFit['e'])], [EC50_response, EC50_response], color = 'navy', linestyle = '--', lw = 0.7)\n",
    "                plt.plot([pDose(curFit['e']), pDose(curFit['e'])], [ymin, EC50_response], color = 'navy', linestyle = '--', lw = 0.7)\n",
    "                plt.show()\n",
    "                \n",
    "                if path:\n",
    "                    g2.savefig(path +'//' + name +'_dr_fit.png', bbox_inches='tight', dpi=600)\n",
    "                \n",
    "                plt.close()\n",
    "\n",
    "        except Exception as e:\n",
    "                print('Fitting curve failed:')\n",
    "                print(e)\n",
    "    if not fitData.empty: \n",
    "        fitData = fitData.set_index('Compound_id') # .round(2)\n",
    "        fitData['N'] = fitData.N.astype(int)\n",
    "        fitData.rename(columns = {'b': 'hill slope', 'c': 'min response', 'd': 'max response', 'e': 'EC50'}, inplace = True)\n",
    "        return fitData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def plot_dr_viability(data = None, y_label = 'Response', path = None):\n",
    "    \"\"\"Plots response vs viability. The DataFrame should contain columns ['Compound', 'Dose','logDose', 'Viability', 'Response'] (at least).\"\"\"\n",
    "    import pandas as pd\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.colors as colors\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    sns.set(context = 'notebook', style = 'white', palette = 'dark')\n",
    "    \n",
    "    df = data[['Compound_id', 'Dose','logDose', 'Viability', 'Response']]\n",
    "    df = df[(df != 0).all(1)]  # drop zero values\n",
    "    df_mean = df.groupby(['Compound_id','Dose'], as_index = False).mean() # calculate response mean values\n",
    "    df_mean['resp_std'] = list(df.groupby(['Compound_id','Dose']).std()['Response'].values) # calculate response std\n",
    "    df_mean['via_std'] = list(df.groupby(['Compound_id','Dose']).std()['Viability'].values) # calculate viability std\n",
    "\n",
    "    for name, group in  df_mean.groupby('Compound_id'):  # group data by compounds\n",
    "        group = group.sort_values('Dose')\n",
    "        error_resp, error_via  = group['resp_std'], group['via_std']\n",
    "          \n",
    "        fig, ax1 = plt.subplots(figsize = (6,6))  \n",
    "        plt.title(name, fontsize = 16)\n",
    "\n",
    "        plot1 = ax1.plot(group['logDose'], group['Response'], 'b', label = 'Response')\n",
    "        ax1.set_xlim(max(group['logDose'])*1.07, min(group['logDose'])*0.9)\n",
    "        ax1.set_ylabel(y_label, fontsize = 16)\n",
    "        ax1.set_ylim(0, df_mean['Response'].max()*1.2)\n",
    "        ax1.errorbar(group['logDose'], group['Response'],yerr = error_resp, fmt ='o', color ='b', ecolor = 'lightblue')\n",
    "\n",
    "        ax2 = ax1.twinx()\n",
    "        plot2 = ax2.plot(group['logDose'], group['Viability'], 'g', label = 'Viability')\n",
    "        ax2.set_xlim(max(group['logDose'])*1.07, min(group['logDose'])*0.9)\n",
    "        ax2.set_ylabel('Viability', fontsize = 16)\n",
    "        ax2.set_ylim(0, 120)\n",
    "        ax2.errorbar(group['logDose'], group['Viability'],yerr=error_via, fmt='o', color='g', ecolor='lightgreen')\n",
    "        ax1.set_xlabel('Dose, um', fontsize = 16)\n",
    "\n",
    "        # create legend\n",
    "        lines = plot1 + plot2\n",
    "        ax1.legend(lines, [l.get_label() for l in lines])\n",
    "        locs, labels = plt.xticks()\n",
    "        new_labels =[]\n",
    "        for loc in locs:\n",
    "            inv_log = lambda x:((10**-x)/(1e-6)) # inverse log calculator to set xticks\n",
    "            inv_x = round(inv_log(loc), 1)\n",
    "            new_labels.append(inv_x)\n",
    "        ax1.set_xticklabels(new_labels) \n",
    "        if path:\n",
    "            plt.savefig(path +'//' + name +'_raw_viability.png', bbox_inches='tight', dpi=600)\n",
    "        plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def prune_compound(df, threshold = -0.15):\n",
    "    \"\"\"This function takes DataFrame of one-compound dose-response data, find maximum activity, \n",
    "    and drops rows starting from treshold-defined reduction of Response. The default value for threshold = -0.15, \n",
    "   it drops rows starting from 15% reduction of Response. The input DataFrame should contain columns \n",
    "   'Compound_id', 'Dose', 'Response'.\n",
    "   \"\"\"\n",
    "    \n",
    "    prunned = pd.DataFrame()\n",
    "    df = df.sort_values('Dose')\n",
    "    curr_max = 0.0000001\n",
    "    groups = df.groupby('Dose')\n",
    "    for name, group in groups:\n",
    "        percent_change = (group['Response'].mean()/curr_max)-1\n",
    "        if group['Response'].mean() > curr_max:\n",
    "            curr_max = group['Response'].mean()\n",
    "        if percent_change > threshold:\n",
    "            prunned = prunned.append(group)\n",
    "    return(prunned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def plot_polynomial(df = None, y_label = 'Response', degree = 2, path = None):\n",
    "    \"\"\"Plot polynomial fit.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.colors as colors\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    try:\n",
    "        df = df[['Compound_id', 'Dose', 'Response']]\n",
    "        df = df[(df != 0).all(1)]  # drop zero values\n",
    "        df['logDose'] = pDose(df['Dose'].astype(float))\n",
    "    except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    # plot response\n",
    "    for name, group in df.groupby('Compound_id'):\n",
    "        mean_group = group.groupby(['Dose'], as_index = False).mean()\n",
    "        g = sns.lmplot('logDose', 'Response', data = mean_group,  fit_reg = False, legend = False, height=6)\n",
    "        g.map(plt.errorbar, 'logDose', 'Response',yerr = list(group.groupby(['Dose']).std()['Response'].values), fmt='o')\n",
    "        plt.xlim(max(group['logDose'])*1.1, min(group['logDose'])*0.9)   \n",
    "        locs, labels = plt.xticks() \n",
    "        g.set_xticklabels([round(inv_log(l), 1) for l in locs]) # inverse log for xticks       \n",
    "        plt.xlabel('Dose (um)')\n",
    "        plt.ylabel(y_label)\n",
    "        plt.title(name)\n",
    "        \n",
    "        # plot polynomial_fit\n",
    "        try:\n",
    "            X  = np.asarray(group['logDose'].values)\n",
    "            Y  = np.asarray(group['Response'].values)\n",
    "            p = np.poly1d(np.polyfit(X,Y,degree))\n",
    "            polyDose = np.linspace(min(group['logDose'])*0.98, max(group['logDose'])*1.02, 256)\n",
    "            plt.plot(polyDose, p(polyDose), color='Navy')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print('Polynomial fit failed:')\n",
    "            print(e)\n",
    "        plt.show()\n",
    "        if path:\n",
    "            g.savefig(path +'//' + name +'_polynomial.png', bbox_inches='tight', dpi=600)   \n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def plot_treatments(df = None, x = None, y = None, column = None, kind = None, ylabel = None, \n",
    "                    palette = None, height = None, aspect = None, save_as = None, path = None):\n",
    "    \"\"\"Creates plot by treatments. If your data has different treatments, set column = 'Treatment'. \n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.colors as colors\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    plot_data = df[df['Status'] != 'Reference'] #filter out the Reference wells\n",
    "    g = sns.catplot(x = x, y = y, data = plot_data, col = column, kind = kind, palette = palette,\n",
    "                    height = height, aspect = aspect, margin_titles = False)\n",
    "    axes = g.axes.flatten()\n",
    "    axes[0].set_ylabel(ylabel)\n",
    "    g.set_xticklabels(rotation = 90)\n",
    "    if path:\n",
    "        plt.savefig(path + '//' + save_as, bbox_inches = 'tight', dpi = 600)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def plot_curve_raw(df = None, x = None, y = None, units = None, hue = None, hue_order = None, xlabel = None,\n",
    "                   ylabel = None, xlimit = None, palette = None, save_as = None, path = None):\n",
    "    \"\"\"Plots raw kinetic curves.  \n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.colors as colors\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    ax = sns.lineplot(data = df, x = x, y = y, units = units, hue = hue, hue_order = hue_order, palette = palette, estimator = None)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlim(0, xlimit)\n",
    "    fig = ax.get_figure()\n",
    "    fig.set_size_inches(10, 7)\n",
    "    \n",
    "    if path:\n",
    "        plt.savefig(path + '//' + save_as, bbox_inches = 'tight', dpi = 600)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def plot_curve_mean(df = None, x = None, y = None, hue = None, hue_order = None, xlabel = None, ylabel = None,\n",
    "                    xlimit = None, palette = None, save_as = None, path = None):\n",
    "    \"\"\"Plots mean kinetic curves. \n",
    "    \"\"\" \n",
    "    import pandas as pd\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.colors as colors\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    ax = sns.lineplot(data = df, x = x, y = y, hue = hue, hue_order = hue_order, palette = palette)\n",
    "    sns.despine()\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlim(0, xlimit)\n",
    "    fig = ax.get_figure()\n",
    "    fig.set_size_inches(10, 7)\n",
    "    if path:\n",
    "         plt.savefig(path + '//' + save_as, bbox_inches = 'tight', dpi = 600)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def pointplot_plate(df = None, x = None, y = None, hue = None, hue_order = None, threshold = None, ylabel = None,\n",
    "                    palette = None,  save_as = None, path  = None):\n",
    "    \"\"\"Creates point plot for the experiment.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.colors as colors\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    g = sns.catplot(data = df, x = x, y = y, hue = hue, height = 6, aspect = 2.5, margin_titles = False,\n",
    "                   palette = palette, hue_order = hue_order)\n",
    "    if threshold:\n",
    "        plt.plot([0, len(df.Well.unique())], [threshold, threshold],'r-')\n",
    "        plt.plot([0, len(df.Well.unique())], [-threshold, -threshold],'r-')\n",
    "    \n",
    "    g.set_xticklabels([])\n",
    "    plt.ylabel(ylabel)\n",
    "    g.despine()\n",
    "    if path:\n",
    "         g.savefig(path +'//' + save_as, bbox_inches = 'tight', dpi = 600)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def df_to_table(df = None, slide = None, left = None, top = None, width = None, height = None, colnames = None):\n",
    "    \"\"\"Converts a Pandas DataFrame to a PowerPoint table on the given slide of a PowerPoint presentation.\n",
    "    The table is a standard Powerpoint table, and can easily be modified with the Powerpoint tools (resizing columns, changing formatting etc).\n",
    "    Source:  https://github.com/robintw/PandasToPowerpoint/blob/master/PandasToPowerpoint.py\n",
    "     \"\"\"\n",
    "    import pandas as pd\n",
    "    from pptx import Presentation\n",
    "    from pptx.util import Inches, Pt\n",
    "    \n",
    "    rows, cols = df.shape\n",
    "    res = slide.shapes.add_table(rows + 1, cols, left, top, width, height)\n",
    "\n",
    "    if colnames is None:\n",
    "        colnames = list(df.columns)\n",
    "        colnames[0] = 'idx'\n",
    "\n",
    "    # Insert the column names\n",
    "    for col_index, col_name in enumerate(colnames):\n",
    "        # Column names can be tuples\n",
    "        if not isinstance(col_name, str):\n",
    "            col_name = ' '.join(col_name)\n",
    "        res.table.cell(0, col_index).text = col_name\n",
    "        paragraph = res.table.cell(0, col_index).text_frame.paragraphs[0]\n",
    "        paragraph.font.size = Pt(9)\n",
    "\n",
    "    #m = df.as_matrix()\n",
    "    m = df.values\n",
    "\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            val = m[row, col]\n",
    "            text = str(val)\n",
    "            res.table.cell(row + 1, col).text = text\n",
    "            paragraph = res.table.cell(row + 1, col).text_frame.paragraphs[0]\n",
    "            paragraph.font.size = Pt(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@exception_handler\n",
    "def create_presentation(path = None):\n",
    "    \"\"\"Creates ppt report from files in the specified folder. \n",
    "    \"\"\"\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    from datetime import date\n",
    "    from pptx import Presentation\n",
    "    from pptx.util import Inches, Pt\n",
    "\n",
    "    report = Presentation('hts_data//templates//ppt_template.pptx')\n",
    "    slide = report.slides.add_slide(report.slide_layouts[6])  \n",
    "    #pic = slide.shapes.add_picture('hts_data//templates//logo.png', left = Inches(3), top = Inches(0.2))\n",
    "    subtitle = slide.shapes.add_textbox(left = Inches(5.), top = Inches(3.5), width = Inches(3), height = Inches(0.5),).text_frame\n",
    "    p = subtitle.paragraphs[0]\n",
    "    run = p.add_run() \n",
    "    run.text = 'Technical Report\\nGenerated on {:%m-%d-%Y}'.format(date.today())\n",
    "    font = run.font\n",
    "    font.size = Pt(18) \n",
    "    files_list = os.listdir(path)\n",
    "    for myfile in files_list:\n",
    "        if 'heatmap.png' in myfile:\n",
    "            slide = report.slides.add_slide(report.slide_layouts[6])\n",
    "            left = top = Inches(0.7)\n",
    "            height = Inches(6)\n",
    "            pic = slide.shapes.add_picture(path + '//' + myfile, left, top, width = Inches(5.8), height= Inches(4))         \n",
    "        elif '.png' in myfile and 'heatmap.png' not in myfile:\n",
    "            slide = report.slides.add_slide(report.slide_layouts[6])\n",
    "            subtitle = slide.shapes.add_textbox(left = Inches(0.5), top = Inches(0.3), width = Inches(2), height = Inches(0.5)).text_frame       \n",
    "            subtitle.text = myfile\n",
    "            left = top = Inches(0.7)\n",
    "            pic = slide.shapes.add_picture(path +'//' + myfile, left, top = Inches(0.8), height= Inches(6))  \n",
    "            left = Inches(0.7)\n",
    "        elif 'csv' in myfile:\n",
    "            try:\n",
    "                table = pd.read_csv(path +'//' + myfile)\n",
    "                if table.shape[0]<30:  \n",
    "                    slide = report.slides.add_slide(report.slide_layouts[6])\n",
    "                    subtitle = slide.shapes.add_textbox(left = Inches(0.5), top = Inches(0.3), width = Inches(2), height = Inches(0.5)).text_frame\n",
    "                    subtitle.text = myfile\n",
    "                    slide_table = df_to_table(table, slide, left = Inches(0.3), top = Inches(1), width = Inches(12.5), height = Inches(0.3)) \n",
    "                left = Inches(0.7)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copyright"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\"> Copyright 2020 onwards, Blavatnik Center for Drug Discovery. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this project's files except in compliance with the License. A copy of the License is provided in the LICENSE file in this repository.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "# export all modules directly from a notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
